{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d1b587-5500-47b8-81fb-9557ed155d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关模块\n",
    "import os\n",
    "import mindspore as ms\n",
    "import mindspore.context as context\n",
    "#transforms.c_transforms用于通用型数据增强，vision.c_transforms用于图像类数据增强\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "#nn模块用于定义网络，model模块用于编译模型，callback模块用于设定监督指标\n",
    "from mindspore import nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import LossMonitor\n",
    "#设定运行模式为图模式，运行硬件为昇腾芯片\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target='GPU') # CPU, GPU\n",
    "# 从OBS导入数据\n",
    "import moxing\n",
    "moxing.file.copy_parallel(src_url=\"obs://cifar-10-bc53/cifar-10\", dst_url='CIFAR10/')\n",
    "data_path = 'CIFAR10/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b6cabf-f628-44dc-8546-76336e514a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir, training=True, batch_size=32, resize=(32, 32),\n",
    "                   rescale=1/(255*0.3081), shift=-0.1307/0.3081, buffer_size=64):\n",
    "    #生成路径\n",
    "    data_dir = os.path.join(data_dir)\n",
    "    #利用Cifar10Dataset方法读cifar10数据集，如果training是True则读取训练集\n",
    "    ds = ms.dataset.Cifar10Dataset(dataset_dir=data_dir, usage='train' if training else 'test')\n",
    "    # 数据增强操作\n",
    "    transforms = [\n",
    "        CV.Resize(resize),  # 调整图像大小\n",
    "        CV.Rescale(rescale, shift),  # 归一化\n",
    "        CV.HWC2CHW(),  # HWC to CHW\n",
    "        CV.RandomRotation(degrees=1),  # 随机旋转图像\n",
    "        # CV.RandomVerticalFlip(),  # 随机垂直翻转\n",
    "        # CV.RandomHorizontalFlip()\n",
    "    ]\n",
    "    #map方法是非常有效的方法，可以整体对数据集进行处理，resize改变数据形状，rescale进行归一化，HWC2CHW改变图像通道\n",
    "    ds = ds.map(input_columns=[\"image\"], operations=transforms)\n",
    "    #利用map方法改变数据集标签的数据类型\n",
    "    ds = ds.map(input_columns=[\"label\"], operations=C.TypeCast(ms.int32))\n",
    "    # shuffle是打乱操作，同时设定了batchsize的大小，并将最后不足一个batch的数据抛弃\n",
    "    ds = ds.shuffle(buffer_size=buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c623055-cd3b-41b3-9101-07681b4bd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型结构，MindSpore中的模型时通过construct定义模型结构，在__init__中初始化各层的对象\n",
    "class LeNet5(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        #定义卷积层，ReLU激活函数，平坦层和全连接层\n",
    "        #conv2d的输入通道为3维，输出为6维，卷积核尺寸为5*5，步长为1，不适用padding\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, stride=1, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, stride=1, pad_mode='valid')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(keep_prob=0.9)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(400, 512)\n",
    "        self.fc1_dropout = nn.Dropout(keep_prob=0.5)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Dense(512, 256)\n",
    "        self.fc2_dropout = nn.Dropout(keep_prob=0.5)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Dense(256,128)\n",
    "        self.fc3_dropout = nn.Dropout(keep_prob=0.7)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Dense(128,64)\n",
    "        self.fc4_dropout = nn.Dropout(keep_prob=0.8)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc5 = nn.Dense(64, 10)\n",
    "        # self.bn5 = nn.BatchNorm1d(32)\n",
    "        # self.fc6 = nn.Dense(32,10)\n",
    "    #构建Lenet5架构，x代表网络的输入\n",
    "    def construct(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.bn1(self.fc1_dropout(self.fc1(x))))\n",
    "        x = self.relu(self.bn2(self.fc2_dropout(self.fc2(x))))\n",
    "        x = self.relu(self.bn3(self.fc3_dropout(self.fc3(x))))\n",
    "        x = self.relu(self.bn4(self.fc4_dropout(self.fc4(x))))\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d70241-2823-41a6-acf9-f9ab72ae2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.train.callback import Callback\n",
    "import numpy as np\n",
    "\n",
    "class EarlyStopping(Callback):\n",
    "    def __init__(self, patience=4, delta=0, monitor='loss', mode='min'):\n",
    "        \"\"\"\n",
    "        Early stopping callback.\n",
    "        \n",
    "        :param patience: 当验证性能在若干个周期内没有改善时，训练会停止。默认是 5。\n",
    "        :param delta: 用于判断改善的阈值。如果 `monitor` 是 'loss'，则损失小于 delta 表示改善。\n",
    "        :param monitor: 用于监控的指标，通常是 'loss' 或 'acc'。\n",
    "        :param mode: 'min' 或 'max'。表示在监控指标上，我们希望是最小化（'min'）还是最大化（'max'）。\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.epochs_without_improvement = 0\n",
    "\n",
    "    def step(self, run_context):\n",
    "        # 获取当前周期的验证损失或准确率\n",
    "        metrics = run_context.original_args()\n",
    "        current_score = metrics[self.monitor]  # 使用 'loss' 或 'acc'\n",
    "\n",
    "        # 判断是否为第一次初始化\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif (self.mode == 'min' and current_score < self.best_score - self.delta) or \\\n",
    "             (self.mode == 'max' and current_score > self.best_score + self.delta):\n",
    "            self.best_score = current_score\n",
    "            self.epochs_without_improvement = 0  # 重置计数器\n",
    "        else:\n",
    "            self.epochs_without_improvement += 1\n",
    "\n",
    "        # 如果在 `patience` 轮内没有改善，则提前停止训练\n",
    "        if self.epochs_without_improvement >= self.patience:\n",
    "            print(f\"Early stopping triggered at epoch {run_context.cur_epoch_num}\")\n",
    "            run_context.request_stop()  # 停止训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333f310d-c623-4540-8919-b7cb46a45b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 余弦退火学习率衰减\n",
    "def lr_schedule(epoch, initial_lr=0.001, total_epochs=50):\n",
    "    if epoch < 5:  # 前5个epoch进行学习率预热\n",
    "        lr = initial_lr * (epoch / 5)\n",
    "    else:\n",
    "        lr = initial_lr * 0.5 * (1 + np.cos(np.pi * (epoch - 5) / (total_epochs - 5)))\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dbb98f9-d811-430c-9cc9-388bfc15c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建训练、验证函数进行模型训练和验证，提供数据路径，设定学习率，epoch数量\n",
    "def train(data_dir, lr=0.0005, momentum=0.9, num_epochs=50):\n",
    "    #调用函数，读取训练集\n",
    "    ds_train = create_dataset(data_dir)\n",
    "    #调用函数，读取验证集\n",
    "    ds_eval = create_dataset(data_dir, training=False)\n",
    "    #构建网络\n",
    "    net = LeNet5()\n",
    "    #设定loss函数\n",
    "    loss = nn.loss.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    #设定优化器\n",
    "    # opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "    opt = nn.Adam(net.trainable_params(),lr)\n",
    "    #设定损失监控\n",
    "    loss_cb = LossMonitor(per_print_times=ds_train.get_dataset_size())\n",
    "     # 创建EarlyStopping回调\n",
    "    early_stopping_cb = EarlyStopping(patience=4,monitor='loss',mode='min')\n",
    "    #编译形成模型\n",
    "    model = Model(net, loss, opt, metrics={'acc', 'loss'})\n",
    "    # 训练网络，dataset_sink_mode为on_device模式\n",
    "    model.train(num_epochs, ds_train, callbacks=[loss_cb,early_stopping_cb], dataset_sink_mode=False)\n",
    "    #用验证机评估网络表现\n",
    "    metrics = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    #输出相关指标\n",
    "    print('Metrics:', metrics)\n",
    "    # for epoch in range(num_epochs):\n",
    "    #     model.train(1, ds_train, callbacks=[loss_cb,early_stopping_cb], dataset_sink_mode=False)\n",
    "    #     metrics = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    #     print('Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cad214e-907f-4d96-9d4c-64b42fb83c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1562, loss is 1.5643280744552612\n",
      "epoch: 2 step: 1562, loss is 1.4399712085723877\n",
      "epoch: 3 step: 1562, loss is 1.293887734413147\n",
      "epoch: 4 step: 1562, loss is 1.081912875175476\n",
      "epoch: 5 step: 1562, loss is 1.0442205667495728\n",
      "epoch: 6 step: 1562, loss is 1.3243683576583862\n",
      "epoch: 7 step: 1562, loss is 1.4306213855743408\n",
      "epoch: 8 step: 1562, loss is 0.9349492788314819\n",
      "epoch: 9 step: 1562, loss is 1.3609750270843506\n",
      "epoch: 10 step: 1562, loss is 1.4849300384521484\n",
      "epoch: 11 step: 1562, loss is 0.9384766221046448\n",
      "epoch: 12 step: 1562, loss is 1.0386909246444702\n",
      "epoch: 13 step: 1562, loss is 1.2069979906082153\n",
      "epoch: 14 step: 1562, loss is 1.4659512042999268\n",
      "epoch: 15 step: 1562, loss is 1.172181487083435\n",
      "epoch: 16 step: 1562, loss is 1.0796278715133667\n",
      "epoch: 17 step: 1562, loss is 1.0796332359313965\n",
      "epoch: 18 step: 1562, loss is 1.1411136388778687\n",
      "epoch: 19 step: 1562, loss is 1.3716362714767456\n",
      "epoch: 20 step: 1562, loss is 0.713984489440918\n",
      "epoch: 21 step: 1562, loss is 0.9227941632270813\n",
      "epoch: 22 step: 1562, loss is 1.038912296295166\n",
      "epoch: 23 step: 1562, loss is 1.3113633394241333\n",
      "epoch: 24 step: 1562, loss is 0.7043943405151367\n",
      "epoch: 25 step: 1562, loss is 0.961093544960022\n",
      "epoch: 26 step: 1562, loss is 0.8219325542449951\n",
      "epoch: 27 step: 1562, loss is 1.1755136251449585\n",
      "epoch: 28 step: 1562, loss is 0.9897106289863586\n",
      "epoch: 29 step: 1562, loss is 0.840211808681488\n",
      "epoch: 30 step: 1562, loss is 1.0254343748092651\n",
      "epoch: 31 step: 1562, loss is 1.1022580862045288\n",
      "epoch: 32 step: 1562, loss is 0.7967864274978638\n",
      "epoch: 33 step: 1562, loss is 0.8125958442687988\n",
      "epoch: 34 step: 1562, loss is 0.9020158648490906\n",
      "epoch: 35 step: 1562, loss is 1.0198616981506348\n",
      "epoch: 36 step: 1562, loss is 0.8508465886116028\n",
      "epoch: 37 step: 1562, loss is 0.6843624711036682\n",
      "epoch: 38 step: 1562, loss is 0.6589563488960266\n",
      "epoch: 39 step: 1562, loss is 0.6689255833625793\n",
      "epoch: 40 step: 1562, loss is 0.8258470892906189\n",
      "epoch: 41 step: 1562, loss is 0.5354859232902527\n",
      "epoch: 42 step: 1562, loss is 0.7229994535446167\n",
      "epoch: 43 step: 1562, loss is 0.8067353963851929\n",
      "epoch: 44 step: 1562, loss is 0.8754791617393494\n",
      "epoch: 45 step: 1562, loss is 0.7882215976715088\n",
      "epoch: 46 step: 1562, loss is 1.0077316761016846\n",
      "epoch: 47 step: 1562, loss is 0.6386092901229858\n",
      "epoch: 48 step: 1562, loss is 0.4723074436187744\n",
      "epoch: 49 step: 1562, loss is 0.8488571047782898\n",
      "epoch: 50 step: 1562, loss is 0.69516521692276\n",
      "Metrics: {'loss': 0.9242939638594786, 'acc': 0.6988181089743589}\n"
     ]
    }
   ],
   "source": [
    "#main函数负责调用之前定义的函数，完成整个训练验证过程\n",
    "if __name__ == \"__main__\":\n",
    "    #argsparse是python的命令行解析的标准模块，可以通过命令行传入参数\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    #设定训练数据路径\n",
    "    parser.add_argument('--data_url', required=False, default=None, help='Location of data.')\n",
    "    parser.add_argument('--train_url', required=False, default=None, help='Location of training outputs.')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    #调用train函数，训练并验证模型\n",
    "    train(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4012606f-b422-44cf-957a-6817363b71f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb32b3-9803-4f81-bf13-301fa9ca4856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8622ebd-2b58-4acc-93e7-d620a3fea963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
